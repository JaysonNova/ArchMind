# æ•°æ®å±‚è¯¦ç»†è®¾è®¡æ–‡æ¡£

## æ–‡æ¡£ç‰ˆæœ¬ä¿¡æ¯

* **ç‰ˆæœ¬ï¼š** v1.0
* **åˆ›å»ºæ—¥æœŸï¼š** 2026-02-01
* **æœ€åæ›´æ–°ï¼š** 2026-02-01
* **æ–‡æ¡£çŠ¶æ€ï¼š** Draft
* **åŸºäºæ–‡æ¡£ï¼š** æ¶æ„è®¾è®¡æ–‡æ¡£ v1.0

---

## 1. æ–‡æ¡£æ¦‚è¿°

### 1.1 æ–‡æ¡£ç›®çš„

æœ¬æ–‡æ¡£è¯¦ç»†æè¿° ArchMind AI æ•°æ®å±‚çš„å®ç°è§„èŒƒï¼ŒåŒ…æ‹¬:
- æ•°æ®åº“ Schema è®¾è®¡
- æ•°æ®è®¿é—®å±‚ (DAO) å®ç°
- TypeScript ç±»å‹å®šä¹‰
- æ•°æ®åº“æ“ä½œå°è£…
- å‘é‡æ•°æ®åº“é›†æˆ

### 1.2 ç›®æ ‡è¯»è€…

- åç«¯å¼€å‘å·¥ç¨‹å¸ˆ
- æ•°æ®åº“ç®¡ç†å‘˜
- ç³»ç»Ÿæ¶æ„å¸ˆ

### 1.3 æŠ€æœ¯æ ˆ

- **æ•°æ®åº“:** SQLite 3.x
- **ORM:** better-sqlite3 ^9.4.0
- **å‘é‡æ•°æ®åº“:** sqlite-vss ^0.1.2
- **ID ç”Ÿæˆ:** nanoid ^5.0.6
- **ç±»å‹ç³»ç»Ÿ:** TypeScript 5.x

---

## 2. æ•°æ®åº“ Schema è®¾è®¡

### 2.1 å®Œæ•´ Schema å®šä¹‰

**æ–‡ä»¶ä½ç½®:** `lib/db/schema.sql`

```sql
-- ============================================
-- æ–‡æ¡£ç®¡ç†ç›¸å…³è¡¨
-- ============================================

-- æ–‡æ¡£è¡¨
CREATE TABLE documents (
  id TEXT PRIMARY KEY,
  title TEXT NOT NULL,
  file_path TEXT NOT NULL,
  file_type TEXT NOT NULL,
  file_size INTEGER,
  content TEXT,
  metadata TEXT,  -- JSON æ ¼å¼å­˜å‚¨é¢å¤–ä¿¡æ¯
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- æ–‡æ¡£å—è¡¨ï¼ˆç”¨äºå‘é‡æ£€ç´¢ï¼‰
CREATE TABLE document_chunks (
  id TEXT PRIMARY KEY,
  document_id TEXT NOT NULL,
  chunk_index INTEGER NOT NULL,
  content TEXT NOT NULL,
  metadata TEXT,  -- JSON æ ¼å¼
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (document_id) REFERENCES documents(id) ON DELETE CASCADE
);

-- ============================================
-- å‘é‡æ£€ç´¢ç›¸å…³è¡¨
-- ============================================

-- å‘é‡ç´¢å¼•è¡¨ï¼ˆsqlite-vss è™šæ‹Ÿè¡¨ï¼‰
CREATE VIRTUAL TABLE vector_index USING vss0(
  embedding(1536)  -- OpenAI text-embedding-3-small ç»´åº¦
);

-- å‘é‡æ˜ å°„è¡¨ï¼ˆå…³è” chunk å’Œ vectorï¼‰
CREATE TABLE vector_mappings (
  id TEXT PRIMARY KEY,
  chunk_id TEXT NOT NULL,
  vector_id INTEGER NOT NULL,
  FOREIGN KEY (chunk_id) REFERENCES document_chunks(id) ON DELETE CASCADE
);

-- ============================================
-- PRD æ–‡æ¡£ç›¸å…³è¡¨
-- ============================================

-- PRD æ–‡æ¡£è¡¨
CREATE TABLE prd_documents (
  id TEXT PRIMARY KEY,
  title TEXT NOT NULL,
  content TEXT NOT NULL,
  user_input TEXT NOT NULL,
  model_used TEXT NOT NULL,
  generation_time INTEGER,  -- ç”Ÿæˆè€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
  token_count INTEGER,      -- Token ä½¿ç”¨é‡
  cost REAL,                -- æˆæœ¬ï¼ˆç¾å…ƒï¼‰
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- PRD æ–‡æ¡£å¼•ç”¨è¡¨ï¼ˆè®°å½•ä½¿ç”¨äº†å“ªäº›å†å²æ–‡æ¡£ï¼‰
CREATE TABLE prd_document_references (
  id TEXT PRIMARY KEY,
  prd_id TEXT NOT NULL,
  document_id TEXT NOT NULL,
  relevance_score REAL,  -- ç›¸å…³æ€§åˆ†æ•°
  FOREIGN KEY (prd_id) REFERENCES prd_documents(id) ON DELETE CASCADE,
  FOREIGN KEY (document_id) REFERENCES documents(id) ON DELETE CASCADE
);

-- ============================================
-- ç³»ç»Ÿé…ç½®ç›¸å…³è¡¨
-- ============================================

-- ç³»ç»Ÿé…ç½®è¡¨ï¼ˆKey-Value å­˜å‚¨ï¼‰
CREATE TABLE system_config (
  key TEXT PRIMARY KEY,
  value TEXT NOT NULL,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- ç”Ÿæˆå†å²è¡¨ï¼ˆå®¡è®¡æ—¥å¿—ï¼‰
CREATE TABLE generation_history (
  id TEXT PRIMARY KEY,
  prd_id TEXT NOT NULL,
  user_input TEXT NOT NULL,
  model_used TEXT NOT NULL,
  success BOOLEAN NOT NULL,
  error_message TEXT,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (prd_id) REFERENCES prd_documents(id) ON DELETE CASCADE
);

-- ============================================
-- ç´¢å¼•å®šä¹‰
-- ============================================

-- æ–‡æ¡£è¡¨ç´¢å¼•
CREATE INDEX idx_documents_created_at ON documents(created_at);
CREATE INDEX idx_documents_file_type ON documents(file_type);

-- æ–‡æ¡£å—è¡¨ç´¢å¼•
CREATE INDEX idx_chunks_document_id ON document_chunks(document_id);

-- å‘é‡æ˜ å°„è¡¨ç´¢å¼•
CREATE INDEX idx_vector_mappings_chunk_id ON vector_mappings(chunk_id);

-- PRD æ–‡æ¡£è¡¨ç´¢å¼•
CREATE INDEX idx_prd_created_at ON prd_documents(created_at);
CREATE INDEX idx_prd_model_used ON prd_documents(model_used);

-- PRD å¼•ç”¨è¡¨ç´¢å¼•
CREATE INDEX idx_prd_refs_prd_id ON prd_document_references(prd_id);
CREATE INDEX idx_prd_refs_document_id ON prd_document_references(document_id);

-- ç”Ÿæˆå†å²è¡¨ç´¢å¼•
CREATE INDEX idx_history_created_at ON generation_history(created_at);
```

### 2.2 è¡¨ç»“æ„è¯´æ˜

#### 2.2.1 documents è¡¨

**ç”¨é€”:** å­˜å‚¨ä¸Šä¼ çš„æ–‡æ¡£å…ƒæ•°æ®å’Œå†…å®¹

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| id | TEXT | ä¸»é”®ï¼Œä½¿ç”¨ nanoid ç”Ÿæˆ |
| title | TEXT | æ–‡æ¡£æ ‡é¢˜ï¼ˆåŸå§‹æ–‡ä»¶åï¼‰ |
| file_path | TEXT | æ–‡ä»¶å­˜å‚¨è·¯å¾„ |
| file_type | TEXT | æ–‡ä»¶ç±»å‹ (pdf, docx, md) |
| file_size | INTEGER | æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰ |
| content | TEXT | æå–çš„æ–‡æœ¬å†…å®¹ |
| metadata | TEXT | JSON æ ¼å¼çš„å…ƒæ•°æ® |
| created_at | DATETIME | åˆ›å»ºæ—¶é—´ |
| updated_at | DATETIME | æ›´æ–°æ—¶é—´ |

**metadata ç¤ºä¾‹:**
```json
{
  "originalName": "äº§å“éœ€æ±‚æ–‡æ¡£.pdf",
  "uploadedAt": "2026-02-01T10:00:00Z",
  "pageCount": 15,
  "author": "Product Team"
}
```

#### 2.2.2 document_chunks è¡¨

**ç”¨é€”:** å­˜å‚¨æ–‡æ¡£åˆ†å—ï¼Œç”¨äºå‘é‡æ£€ç´¢

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| id | TEXT | ä¸»é”® |
| document_id | TEXT | å…³è”çš„æ–‡æ¡£ ID |
| chunk_index | INTEGER | å—ç´¢å¼•ï¼ˆä» 0 å¼€å§‹ï¼‰ |
| content | TEXT | å—å†…å®¹ |
| metadata | TEXT | JSON æ ¼å¼çš„å…ƒæ•°æ® |
| created_at | DATETIME | åˆ›å»ºæ—¶é—´ |

**åˆ†å—ç­–ç•¥:**
- Chunk Size: 1000 å­—ç¬¦
- Overlap: 200 å­—ç¬¦
- ä½¿ç”¨ RecursiveCharacterTextSplitter

#### 2.2.3 vector_index è¡¨

**ç”¨é€”:** sqlite-vss è™šæ‹Ÿè¡¨ï¼Œå­˜å‚¨å‘é‡

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| rowid | INTEGER | è‡ªåŠ¨ç”Ÿæˆçš„è¡Œ ID |
| embedding | BLOB | 1536 ç»´å‘é‡ |

**å‘é‡æ¥æº:**
- OpenAI text-embedding-3-small
- ç»´åº¦: 1536
- ç›¸ä¼¼åº¦è®¡ç®—: ä½™å¼¦ç›¸ä¼¼åº¦

#### 2.2.4 vector_mappings è¡¨

**ç”¨é€”:** å…³è”æ–‡æ¡£å—å’Œå‘é‡

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| id | TEXT | ä¸»é”® |
| chunk_id | TEXT | æ–‡æ¡£å— ID |
| vector_id | INTEGER | å‘é‡è¡¨çš„ rowid |

#### 2.2.5 prd_documents è¡¨

**ç”¨é€”:** å­˜å‚¨ç”Ÿæˆçš„ PRD æ–‡æ¡£

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| id | TEXT | ä¸»é”® |
| title | TEXT | PRD æ ‡é¢˜ |
| content | TEXT | PRD å†…å®¹ï¼ˆMarkdownï¼‰ |
| user_input | TEXT | ç”¨æˆ·è¾“å…¥çš„éœ€æ±‚ |
| model_used | TEXT | ä½¿ç”¨çš„ AI æ¨¡å‹ |
| generation_time | INTEGER | ç”Ÿæˆè€—æ—¶ï¼ˆæ¯«ç§’ï¼‰ |
| token_count | INTEGER | Token ä½¿ç”¨é‡ |
| cost | REAL | æˆæœ¬ï¼ˆç¾å…ƒï¼‰ |
| created_at | DATETIME | åˆ›å»ºæ—¶é—´ |
| updated_at | DATETIME | æ›´æ–°æ—¶é—´ |

#### 2.2.6 prd_document_references è¡¨

**ç”¨é€”:** è®°å½• PRD å¼•ç”¨çš„å†å²æ–‡æ¡£

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| id | TEXT | ä¸»é”® |
| prd_id | TEXT | PRD æ–‡æ¡£ ID |
| document_id | TEXT | å¼•ç”¨çš„æ–‡æ¡£ ID |
| relevance_score | REAL | ç›¸å…³æ€§åˆ†æ•° (0-1) |

---

## 3. æ•°æ®åº“å®¢æˆ·ç«¯å®ç°

### 3.1 DatabaseClient ç±»

**æ–‡ä»¶ä½ç½®:** `lib/db/client.ts`

```typescript
import Database from 'better-sqlite3';
import path from 'path';
import fs from 'fs';

export class DatabaseClient {
  private db: Database.Database;
  private static instance: DatabaseClient;

  private constructor() {
    const dbPath = process.env.DATABASE_PATH || path.join(process.cwd(), 'data', 'database.db');

    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    const dbDir = path.dirname(dbPath);
    if (!fs.existsSync(dbDir)) {
      fs.mkdirSync(dbDir, { recursive: true });
    }

    this.db = new Database(dbPath);
    this.db.pragma('journal_mode = WAL'); // æ€§èƒ½ä¼˜åŒ–
    this.db.pragma('foreign_keys = ON');  // å¯ç”¨å¤–é”®çº¦æŸ
  }

  public static getInstance(): DatabaseClient {
    if (!DatabaseClient.instance) {
      DatabaseClient.instance = new DatabaseClient();
    }
    return DatabaseClient.instance;
  }

  public getDb(): Database.Database {
    return this.db;
  }

  // äº‹åŠ¡æ”¯æŒ
  public transaction<T>(fn: () => T): T {
    const transaction = this.db.transaction(fn);
    return transaction();
  }

  // æ‰¹é‡æ’å…¥ä¼˜åŒ–
  public batchInsert(table: string, records: any[]): void {
    if (records.length === 0) return;

    const keys = Object.keys(records[0]);
    const placeholders = keys.map(() => '?').join(', ');
    const sql = `INSERT INTO ${table} (${keys.join(', ')}) VALUES (${placeholders})`;

    const insert = this.db.prepare(sql);
    const insertMany = this.db.transaction((records: any[]) => {
      for (const record of records) {
        insert.run(...keys.map(k => record[k]));
      }
    });

    insertMany(records);
  }

  // å¥åº·æ£€æŸ¥
  public healthCheck(): boolean {
    try {
      this.db.prepare('SELECT 1').get();
      return true;
    } catch {
      return false;
    }
  }

  // å…³é—­è¿æ¥
  public close(): void {
    this.db.close();
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const db = DatabaseClient.getInstance().getDb();
export default db;
```

### 3.2 è®¾è®¡æ¨¡å¼è¯´æ˜

**å•ä¾‹æ¨¡å¼ (Singleton Pattern):**
- ç¡®ä¿æ•´ä¸ªåº”ç”¨åªæœ‰ä¸€ä¸ªæ•°æ®åº“è¿æ¥å®ä¾‹
- é¿å…å¤šæ¬¡æ‰“å¼€æ•°æ®åº“è¿æ¥å¯¼è‡´çš„èµ„æºæµªè´¹
- çº¿ç¨‹å®‰å…¨ï¼ˆNode.js å•çº¿ç¨‹ç¯å¢ƒï¼‰

**æ€§èƒ½ä¼˜åŒ–:**
- WAL (Write-Ahead Logging) æ¨¡å¼: æå‡å¹¶å‘å†™å…¥æ€§èƒ½
- å¤–é”®çº¦æŸ: ç¡®ä¿æ•°æ®å®Œæ•´æ€§
- äº‹åŠ¡æ”¯æŒ: æ‰¹é‡æ“ä½œçš„åŸå­æ€§

---

## 4. TypeScript ç±»å‹å®šä¹‰

### 4.1 æ–‡æ¡£ç›¸å…³ç±»å‹

**æ–‡ä»¶ä½ç½®:** `types/document.ts`

```typescript
export interface Document {
  id: string;
  title: string;
  filePath: string;
  fileType: string;
  fileSize: number;
  content: string;
  metadata: Record<string, any>;
  createdAt: Date;
  updatedAt: Date;
}

export interface DocumentChunk {
  id: string;
  documentId: string;
  chunkIndex: number;
  content: string;
  metadata: Record<string, any>;
  createdAt: Date;
}

export interface VectorMapping {
  id: string;
  chunkId: string;
  vectorId: number;
}
```

### 4.2 PRD ç›¸å…³ç±»å‹

**æ–‡ä»¶ä½ç½®:** `types/prd.ts`

```typescript
export interface PRDDocument {
  id: string;
  title: string;
  content: string;
  userInput: string;
  modelUsed: string;
  generationTime?: number;
  tokenCount?: number;
  cost?: number;
  createdAt: Date;
  updatedAt: Date;
}

export interface PRDDocumentReference {
  id: string;
  prdId: string;
  documentId: string;
  relevanceScore?: number;
}

export interface GenerationHistory {
  id: string;
  prdId: string;
  userInput: string;
  modelUsed: string;
  success: boolean;
  errorMessage?: string;
  createdAt: Date;
}
```

---

## 5. æ•°æ®è®¿é—®å±‚ (DAO) å®ç°

### 5.1 DocumentDAO - æ–‡æ¡£æ•°æ®è®¿é—®

**æ–‡ä»¶ä½ç½®:** `lib/db/dao/document-dao.ts`

```typescript
import { db } from '../client';
import type { Document } from '@/types/document';
import { nanoid } from 'nanoid';

export class DocumentDAO {
  // åˆ›å»ºæ–‡æ¡£
  static create(doc: Omit<Document, 'id' | 'createdAt' | 'updatedAt'>): Document {
    const id = nanoid();
    const now = new Date().toISOString();

    const stmt = db.prepare(`
      INSERT INTO documents (id, title, file_path, file_type, file_size, content, metadata, created_at, updated_at)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    `);

    stmt.run(
      id,
      doc.title,
      doc.filePath,
      doc.fileType,
      doc.fileSize,
      doc.content,
      JSON.stringify(doc.metadata || {}),
      now,
      now
    );

    return this.findById(id)!;
  }

  // æŸ¥è¯¢å•ä¸ªæ–‡æ¡£
  static findById(id: string): Document | null {
    const stmt = db.prepare('SELECT * FROM documents WHERE id = ?');
    const row = stmt.get(id) as any;

    if (!row) return null;

    return {
      id: row.id,
      title: row.title,
      filePath: row.file_path,
      fileType: row.file_type,
      fileSize: row.file_size,
      content: row.content,
      metadata: JSON.parse(row.metadata || '{}'),
      createdAt: new Date(row.created_at),
      updatedAt: new Date(row.updated_at),
    };
  }

  // æŸ¥è¯¢æ‰€æœ‰æ–‡æ¡£
  static findAll(options?: {
    limit?: number;
    offset?: number;
    orderBy?: 'created_at' | 'updated_at' | 'title';
    order?: 'ASC' | 'DESC';
  }): Document[] {
    const { limit = 50, offset = 0, orderBy = 'created_at', order = 'DESC' } = options || {};

    const stmt = db.prepare(`
      SELECT * FROM documents
      ORDER BY ${orderBy} ${order}
      LIMIT ? OFFSET ?
    `);

    const rows = stmt.all(limit, offset) as any[];

    return rows.map(row => ({
      id: row.id,
      title: row.title,
      filePath: row.file_path,
      fileType: row.file_type,
      fileSize: row.file_size,
      content: row.content,
      metadata: JSON.parse(row.metadata || '{}'),
      createdAt: new Date(row.created_at),
      updatedAt: new Date(row.updated_at),
    }));
  }

  // æ›´æ–°æ–‡æ¡£
  static update(id: string, updates: Partial<Document>): Document | null {
    const now = new Date().toISOString();
    const fields: string[] = [];
    const values: any[] = [];

    if (updates.title !== undefined) {
      fields.push('title = ?');
      values.push(updates.title);
    }
    if (updates.content !== undefined) {
      fields.push('content = ?');
      values.push(updates.content);
    }
    if (updates.metadata !== undefined) {
      fields.push('metadata = ?');
      values.push(JSON.stringify(updates.metadata));
    }

    fields.push('updated_at = ?');
    values.push(now);
    values.push(id);

    const stmt = db.prepare(`
      UPDATE documents
      SET ${fields.join(', ')}
      WHERE id = ?
    `);

    stmt.run(...values);
    return this.findById(id);
  }

  // åˆ é™¤æ–‡æ¡£
  static delete(id: string): boolean {
    const stmt = db.prepare('DELETE FROM documents WHERE id = ?');
    const result = stmt.run(id);
    return result.changes > 0;
  }

  // ç»Ÿè®¡æ–‡æ¡£æ•°é‡
  static count(): number {
    const stmt = db.prepare('SELECT COUNT(*) as count FROM documents');
    const result = stmt.get() as { count: number };
    return result.count;
  }

  // æŒ‰æ–‡ä»¶ç±»å‹æŸ¥è¯¢
  static findByFileType(fileType: string): Document[] {
    const stmt = db.prepare('SELECT * FROM documents WHERE file_type = ? ORDER BY created_at DESC');
    const rows = stmt.all(fileType) as any[];

    return rows.map(row => ({
      id: row.id,
      title: row.title,
      filePath: row.file_path,
      fileType: row.file_type,
      fileSize: row.file_size,
      content: row.content,
      metadata: JSON.parse(row.metadata || '{}'),
      createdAt: new Date(row.created_at),
      updatedAt: new Date(row.updated_at),
    }));
  }
}
```

### 5.2 DocumentChunkDAO - æ–‡æ¡£å—æ•°æ®è®¿é—®

**æ–‡ä»¶ä½ç½®:** `lib/db/dao/document-chunk-dao.ts`

```typescript
import { db } from '../client';
import type { DocumentChunk } from '@/types/document';
import { nanoid } from 'nanoid';

export class DocumentChunkDAO {
  // æ‰¹é‡åˆ›å»ºæ–‡æ¡£å—
  static createMany(chunks: Omit<DocumentChunk, 'id' | 'createdAt'>[]): DocumentChunk[] {
    const now = new Date().toISOString();
    const stmt = db.prepare(`
      INSERT INTO document_chunks (id, document_id, chunk_index, content, metadata, created_at)
      VALUES (?, ?, ?, ?, ?, ?)
    `);

    const insertMany = db.transaction((chunks: any[]) => {
      const ids: string[] = [];
      for (const chunk of chunks) {
        const id = nanoid();
        stmt.run(
          id,
          chunk.documentId,
          chunk.chunkIndex,
          chunk.content,
          JSON.stringify(chunk.metadata || {}),
          now
        );
        ids.push(id);
      }
      return ids;
    });

    const ids = insertMany(chunks);
    return this.findByIds(ids);
  }

  // æŒ‰ ID æ‰¹é‡æŸ¥è¯¢
  static findByIds(ids: string[]): DocumentChunk[] {
    if (ids.length === 0) return [];

    const placeholders = ids.map(() => '?').join(', ');
    const stmt = db.prepare(`
      SELECT * FROM document_chunks WHERE id IN (${placeholders})
    `);

    const rows = stmt.all(...ids) as any[];

    return rows.map(row => ({
      id: row.id,
      documentId: row.document_id,
      chunkIndex: row.chunk_index,
      content: row.content,
      metadata: JSON.parse(row.metadata || '{}'),
      createdAt: new Date(row.created_at),
    }));
  }

  // æŒ‰æ–‡æ¡£ ID æŸ¥è¯¢æ‰€æœ‰å—
  static findByDocumentId(documentId: string): DocumentChunk[] {
    const stmt = db.prepare(`
      SELECT * FROM document_chunks
      WHERE document_id = ?
      ORDER BY chunk_index ASC
    `);

    const rows = stmt.all(documentId) as any[];

    return rows.map(row => ({
      id: row.id,
      documentId: row.document_id,
      chunkIndex: row.chunk_index,
      content: row.content,
      metadata: JSON.parse(row.metadata || '{}'),
      createdAt: new Date(row.created_at),
    }));
  }

  // åˆ é™¤æ–‡æ¡£çš„æ‰€æœ‰å—
  static deleteByDocumentId(documentId: string): number {
    const stmt = db.prepare('DELETE FROM document_chunks WHERE document_id = ?');
    const result = stmt.run(documentId);
    return result.changes;
  }

  // ç»Ÿè®¡æ–‡æ¡£çš„å—æ•°é‡
  static countByDocumentId(documentId: string): number {
    const stmt = db.prepare('SELECT COUNT(*) as count FROM document_chunks WHERE document_id = ?');
    const result = stmt.get(documentId) as { count: number };
    return result.count;
  }
}
```

### 5.3 VectorDAO - å‘é‡æ•°æ®è®¿é—®

**æ–‡ä»¶ä½ç½®:** `lib/db/dao/vector-dao.ts`

```typescript
import { db } from '../client';
import { nanoid } from 'nanoid';

export interface VectorMapping {
  id: string;
  chunkId: string;
  vectorId: number;
}

export class VectorDAO {
  // æ·»åŠ å‘é‡
  static addVector(chunkId: string, embedding: number[]): string {
    // æ’å…¥å‘é‡åˆ° vss0 è¡¨
    const insertVector = db.prepare(`
      INSERT INTO vector_index (embedding) VALUES (?)
    `);

    const result = insertVector.run(JSON.stringify(embedding));
    const vectorId = result.lastInsertRowid as number;

    // åˆ›å»ºæ˜ å°„
    const id = nanoid();
    const insertMapping = db.prepare(`
      INSERT INTO vector_mappings (id, chunk_id, vector_id)
      VALUES (?, ?, ?)
    `);

    insertMapping.run(id, chunkId, vectorId);

    return id;
  }

  // æ‰¹é‡æ·»åŠ å‘é‡
  static addVectors(chunks: Array<{ chunkId: string; embedding: number[] }>): string[] {
    const insertVector = db.prepare(`
      INSERT INTO vector_index (embedding) VALUES (?)
    `);

    const insertMapping = db.prepare(`
      INSERT INTO vector_mappings (id, chunk_id, vector_id)
      VALUES (?, ?, ?)
    `);

    const addMany = db.transaction((chunks: any[]) => {
      const ids: string[] = [];
      for (const chunk of chunks) {
        const vectorResult = insertVector.run(JSON.stringify(chunk.embedding));
        const vectorId = vectorResult.lastInsertRowid as number;

        const id = nanoid();
        insertMapping.run(id, chunk.chunkId, vectorId);
        ids.push(id);
      }
      return ids;
    });

    return addMany(chunks);
  }

  // å‘é‡ç›¸ä¼¼åº¦æœç´¢
  static similaritySearch(
    queryEmbedding: number[],
    limit: number = 5,
    threshold: number = 0.7
  ): Array<{ chunkId: string; score: number }> {
    const stmt = db.prepare(`
      SELECT
        vm.chunk_id,
        vss_distance(vi.embedding, ?) as distance
      FROM vector_index vi
      JOIN vector_mappings vm ON vi.rowid = vm.vector_id
      WHERE vss_distance(vi.embedding, ?) < ?
      ORDER BY distance ASC
      LIMIT ?
    `);

    const embeddingStr = JSON.stringify(queryEmbedding);
    const maxDistance = 1 - threshold;

    const results = stmt.all(embeddingStr, embeddingStr, maxDistance, limit) as any[];

    return results.map(row => ({
      chunkId: row.chunk_id,
      score: 1 - row.distance,
    }));
  }

  // åˆ é™¤æ–‡æ¡£çš„æ‰€æœ‰å‘é‡
  static deleteByChunkIds(chunkIds: string[]): number {
    if (chunkIds.length === 0) return 0;

    const placeholders = chunkIds.map(() => '?').join(', ');
    const getVectorIds = db.prepare(`
      SELECT vector_id FROM vector_mappings WHERE chunk_id IN (${placeholders})
    `);

    const vectorIds = (getVectorIds.all(...chunkIds) as any[]).map(row => row.vector_id);

    if (vectorIds.length === 0) return 0;

    const deleteVectors = db.prepare(`
      DELETE FROM vector_index WHERE rowid IN (${vectorIds.map(() => '?').join(', ')})
    `);

    const deleteMappings = db.prepare(`
      DELETE FROM vector_mappings WHERE chunk_id IN (${placeholders})
    `);

    const deleteAll = db.transaction(() => {
      deleteVectors.run(...vectorIds);
      deleteMappings.run(...chunkIds);
    });

    deleteAll();
    return vectorIds.length;
  }

  // ç»Ÿè®¡å‘é‡æ•°é‡
  static count(): number {
    const stmt = db.prepare('SELECT COUNT(*) as count FROM vector_mappings');
    const result = stmt.get() as { count: number };
    return result.count;
  }
}
```

### 5.4 PRDDAO - PRD æ–‡æ¡£æ•°æ®è®¿é—®

**æ–‡ä»¶ä½ç½®:** `lib/db/dao/prd-dao.ts`

```typescript
import { db } from '../client';
import type { PRDDocument, PRDDocumentReference } from '@/types/prd';
import { nanoid } from 'nanoid';

export class PRDDAO {
  // åˆ›å»º PRD æ–‡æ¡£
  static create(prd: Omit<PRDDocument, 'id' | 'createdAt' | 'updatedAt'>): PRDDocument {
    const id = nanoid();
    const now = new Date().toISOString();

    const stmt = db.prepare(`
      INSERT INTO prd_documents (
        id, title, content, user_input, model_used,
        generation_time, token_count, cost, created_at, updated_at
      )
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `);

    stmt.run(
      id,
      prd.title,
      prd.content,
      prd.userInput,
      prd.modelUsed,
      prd.generationTime || null,
      prd.tokenCount || null,
      prd.cost || null,
      now,
      now
    );

    return this.findById(id)!;
  }

  // æŸ¥è¯¢å•ä¸ª PRD
  static findById(id: string): PRDDocument | null {
    const stmt = db.prepare('SELECT * FROM prd_documents WHERE id = ?');
    const row = stmt.get(id) as any;

    if (!row) return null;

    return {
      id: row.id,
      title: row.title,
      content: row.content,
      userInput: row.user_input,
      modelUsed: row.model_used,
      generationTime: row.generation_time,
      tokenCount: row.token_count,
      cost: row.cost,
      createdAt: new Date(row.created_at),
      updatedAt: new Date(row.updated_at),
    };
  }

  // æŸ¥è¯¢æ‰€æœ‰ PRD
  static findAll(options?: {
    limit?: number;
    offset?: number;
    orderBy?: 'created_at' | 'updated_at';
    order?: 'ASC' | 'DESC';
  }): PRDDocument[] {
    const { limit = 50, offset = 0, orderBy = 'created_at', order = 'DESC' } = options || {};

    const stmt = db.prepare(`
      SELECT * FROM prd_documents
      ORDER BY ${orderBy} ${order}
      LIMIT ? OFFSET ?
    `);

    const rows = stmt.all(limit, offset) as any[];

    return rows.map(row => ({
      id: row.id,
      title: row.title,
      content: row.content,
      userInput: row.user_input,
      modelUsed: row.model_used,
      generationTime: row.generation_time,
      tokenCount: row.token_count,
      cost: row.cost,
      createdAt: new Date(row.created_at),
      updatedAt: new Date(row.updated_at),
    }));
  }

  // æ·»åŠ æ–‡æ¡£å¼•ç”¨
  static addReferences(prdId: string, documentIds: string[], relevanceScores?: number[]): void {
    const stmt = db.prepare(`
      INSERT INTO prd_document_references (id, prd_id, document_id, relevance_score)
      VALUES (?, ?, ?, ?)
    `);

    const insertMany = db.transaction((refs: any[]) => {
      for (const ref of refs) {
        stmt.run(ref.id, ref.prdId, ref.documentId, ref.relevanceScore);
      }
    });

    const refs = documentIds.map((docId, index) => ({
      id: nanoid(),
      prdId,
      documentId: docId,
      relevanceScore: relevanceScores?.[index] || null,
    }));

    insertMany(refs);
  }

  // è·å– PRD çš„å¼•ç”¨æ–‡æ¡£
  static getReferences(prdId: string): PRDDocumentReference[] {
    const stmt = db.prepare(`
      SELECT * FROM prd_document_references
      WHERE prd_id = ?
      ORDER BY relevance_score DESC
    `);

    const rows = stmt.all(prdId) as any[];

    return rows.map(row => ({
      id: row.id,
      prdId: row.prd_id,
      documentId: row.document_id,
      relevanceScore: row.relevance_score,
    }));
  }

  // åˆ é™¤ PRD
  static delete(id: string): boolean {
    const stmt = db.prepare('DELETE FROM prd_documents WHERE id = ?');
    const result = stmt.run(id);
    return result.changes > 0;
  }

  // ç»Ÿè®¡ PRD æ•°é‡
  static count(): number {
    const stmt = db.prepare('SELECT COUNT(*) as count FROM prd_documents');
    const result = stmt.get() as { count: number };
    return result.count;
  }

  // æŒ‰æ¨¡å‹ç»Ÿè®¡ä½¿ç”¨æƒ…å†µ
  static getModelUsageStats(): Array<{ model: string; count: number; totalCost: number }> {
    const stmt = db.prepare(`
      SELECT
        model_used as model,
        COUNT(*) as count,
        COALESCE(SUM(cost), 0) as totalCost
      FROM prd_documents
      GROUP BY model_used
      ORDER BY count DESC
    `);

    return stmt.all() as any[];
  }
}
```

---

## 6. æ•°æ®åº“åˆå§‹åŒ–

### 6.1 åˆå§‹åŒ–è„šæœ¬

**æ–‡ä»¶ä½ç½®:** `scripts/init-db.ts`

```typescript
import fs from 'fs';
import path from 'path';
import Database from 'better-sqlite3';

async function initDatabase() {
  console.log('ğŸš€ Initializing database...');

  const dbPath = process.env.DATABASE_PATH || path.join(process.cwd(), 'data', 'database.db');
  const dbDir = path.dirname(dbPath);

  try {
    // ç¡®ä¿ç›®å½•å­˜åœ¨
    if (!fs.existsSync(dbDir)) {
      fs.mkdirSync(dbDir, { recursive: true });
      console.log('ğŸ“ Created data directory');
    }

    const db = new Database(dbPath);

    // å°è¯•åŠ è½½ sqlite-vss æ‰©å±•
    try {
      db.loadExtension('vss0');
      console.log('âœ… sqlite-vss extension loaded');
    } catch (error) {
      console.warn('âš ï¸  sqlite-vss extension not available');
      console.warn('   Vector search will not work until sqlite-vss is installed');
      console.warn('   Run: npm install sqlite-vss');
    }

    // è¯»å– schema æ–‡ä»¶
    const schemaPath = path.join(process.cwd(), 'lib', 'db', 'schema.sql');
    const schema = fs.readFileSync(schemaPath, 'utf-8');

    // åˆ†å‰²å¹¶æ‰§è¡Œæ¯ä¸ª SQL è¯­å¥
    const statements = schema
      .split(';')
      .map(s => s.trim())
      .filter(s => s.length > 0);

    for (const statement of statements) {
      try {
        db.exec(statement);
      } catch (error: any) {
        if (!error.message.includes('already exists')) {
          console.error('Error executing statement:', statement.substring(0, 100));
          throw error;
        }
      }
    }

    console.log('âœ… Database initialized successfully!');
    console.log('ğŸ“ Database location:', dbPath);

    db.close();
  } catch (error) {
    console.error('âŒ Error initializing database:', error);
    process.exit(1);
  }
}

initDatabase();
```

---

## 7. ä½¿ç”¨ç¤ºä¾‹

### 7.1 æ–‡æ¡£ç®¡ç†ç¤ºä¾‹

```typescript
import { DocumentDAO } from '@/lib/db/dao/document-dao';
import { DocumentChunkDAO } from '@/lib/db/dao/document-chunk-dao';
import { VectorDAO } from '@/lib/db/dao/vector-dao';

// åˆ›å»ºæ–‡æ¡£
const document = DocumentDAO.create({
  title: 'äº§å“éœ€æ±‚æ–‡æ¡£.pdf',
  filePath: '/uploads/abc123.pdf',
  fileType: 'pdf',
  fileSize: 1024000,
  content: 'è¿™æ˜¯æ–‡æ¡£å†…å®¹...',
  metadata: {
    author: 'Product Team',
    pageCount: 15,
  },
});

// æŸ¥è¯¢æ–‡æ¡£
const doc = DocumentDAO.findById(document.id);
const allDocs = DocumentDAO.findAll({ limit: 10, orderBy: 'created_at' });

// æ›´æ–°æ–‡æ¡£
DocumentDAO.update(document.id, {
  title: 'æ›´æ–°åçš„æ ‡é¢˜',
  metadata: { ...doc!.metadata, version: 2 },
});

// åˆ é™¤æ–‡æ¡£
DocumentDAO.delete(document.id);
```

### 7.2 å‘é‡æ£€ç´¢ç¤ºä¾‹

```typescript
import { VectorDAO } from '@/lib/db/dao/vector-dao';
import { DocumentChunkDAO } from '@/lib/db/dao/document-chunk-dao';

// åˆ›å»ºæ–‡æ¡£å—
const chunks = DocumentChunkDAO.createMany([
  {
    documentId: 'doc123',
    chunkIndex: 0,
    content: 'ç¬¬ä¸€æ®µå†…å®¹...',
    metadata: {},
  },
  {
    documentId: 'doc123',
    chunkIndex: 1,
    content: 'ç¬¬äºŒæ®µå†…å®¹...',
    metadata: {},
  },
]);

// æ·»åŠ å‘é‡
const embeddings = [
  [0.1, 0.2, 0.3, /* ... 1536 dimensions */],
  [0.4, 0.5, 0.6, /* ... 1536 dimensions */],
];

VectorDAO.addVectors(
  chunks.map((chunk, index) => ({
    chunkId: chunk.id,
    embedding: embeddings[index],
  }))
);

// ç›¸ä¼¼åº¦æœç´¢
const queryEmbedding = [0.15, 0.25, 0.35, /* ... */];
const results = VectorDAO.similaritySearch(queryEmbedding, 5, 0.7);

// è·å–åŒ¹é…çš„æ–‡æ¡£å—
const matchedChunks = DocumentChunkDAO.findByIds(results.map(r => r.chunkId));
```

---

## 8. æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº† ArchMind AI æ•°æ®å±‚çš„å®Œæ•´å®ç°è§„èŒƒï¼ŒåŒ…æ‹¬:

âœ… **å®Œæ•´çš„æ•°æ®åº“ Schema** - 8 å¼ è¡¨ï¼Œå®Œæ•´ç´¢å¼•
âœ… **æ•°æ®åº“å®¢æˆ·ç«¯** - å•ä¾‹æ¨¡å¼ï¼Œäº‹åŠ¡æ”¯æŒï¼Œæ€§èƒ½ä¼˜åŒ–
âœ… **TypeScript ç±»å‹å®šä¹‰** - å®Œæ•´çš„ç±»å‹å®‰å…¨
âœ… **DAO å±‚å®ç°** - 4 ä¸ªæ ¸å¿ƒ DAO ç±»
âœ… **å‘é‡æ•°æ®åº“é›†æˆ** - sqlite-vss é›†æˆæ–¹æ¡ˆ
âœ… **åˆå§‹åŒ–è„šæœ¬** - è‡ªåŠ¨åŒ–æ•°æ®åº“åˆå§‹åŒ–
âœ… **ä½¿ç”¨ç¤ºä¾‹** - å®é™…ä»£ç ç¤ºä¾‹

**å…³é”®è®¾è®¡å†³ç­–:**
- ä½¿ç”¨ SQLite å®ç°æœ¬åœ°ä¼˜å…ˆæ¶æ„
- DAO æ¨¡å¼å°è£…æ•°æ®è®¿é—®é€»è¾‘
- å•ä¾‹æ¨¡å¼ç®¡ç†æ•°æ®åº“è¿æ¥
- WAL æ¨¡å¼ä¼˜åŒ–å¹¶å‘æ€§èƒ½
- å¤–é”®çº¦æŸç¡®ä¿æ•°æ®å®Œæ•´æ€§
- JSON å­—æ®µå­˜å‚¨çµæ´»çš„å…ƒæ•°æ®

**ä¸‹ä¸€æ­¥:**
- å®ç° RAG å¼•æ“è¯¦ç»†è®¾è®¡
- å®ç° AI æœåŠ¡å±‚è¯¦ç»†è®¾è®¡
- å®ç° API å±‚è¯¦ç»†è®¾è®¡

