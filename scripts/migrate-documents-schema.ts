#!/usr/bin/env node

/**
 * æ•°æ®åº“è¿ç§»è„šæœ¬ - æ‰©å±• documents è¡¨
 *
 * æ·»åŠ å­˜å‚¨ç›¸å…³å­—æ®µ:
 * - storage_provider (å­˜å‚¨æä¾›å•†)
 * - storage_bucket (å­˜å‚¨æ¡¶)
 * - storage_key (å¯¹è±¡é”®)
 * - content_hash (æ–‡ä»¶å“ˆå¸Œï¼Œç”¨äºå»é‡)
 * - processing_status (å¤„ç†çŠ¶æ€)
 * - processing_error (å¤„ç†é”™è¯¯ä¿¡æ¯)
 * - retry_count (é‡è¯•æ¬¡æ•°)
 * - chunks_count (å—æ•°é‡)
 * - vectors_count (å‘é‡æ•°é‡)
 * - processing_started_at (å¤„ç†å¼€å§‹æ—¶é—´)
 * - processing_completed_at (å¤„ç†å®Œæˆæ—¶é—´)
 *
 * ä½¿ç”¨æ–¹å¼:
 * pnpm tsx scripts/migrate-documents-schema.ts
 */

import 'dotenv/config'
import { dbClient } from '../lib/db/client'

async function migrateDocumentsSchema() {
  console.log('ğŸ”„ å¼€å§‹è¿ç§» documents è¡¨ç»“æ„...\n')

  try {
    // 1. æ·»åŠ å­˜å‚¨ç›¸å…³å­—æ®µ
    console.log('1ï¸âƒ£ æ·»åŠ å­˜å‚¨ç›¸å…³å­—æ®µ...')
    await dbClient.query(`
      ALTER TABLE documents
      ADD COLUMN IF NOT EXISTS storage_provider TEXT DEFAULT 'local',
      ADD COLUMN IF NOT EXISTS storage_bucket TEXT,
      ADD COLUMN IF NOT EXISTS storage_key TEXT,
      ADD COLUMN IF NOT EXISTS content_hash TEXT
    `)
    console.log('   âœ… å­˜å‚¨å­—æ®µæ·»åŠ æˆåŠŸ\n')

    // 2. æ·»åŠ å¤„ç†çŠ¶æ€å­—æ®µ
    console.log('2ï¸âƒ£ æ·»åŠ å¤„ç†çŠ¶æ€å­—æ®µ...')
    await dbClient.query(`
      ALTER TABLE documents
      ADD COLUMN IF NOT EXISTS processing_status TEXT DEFAULT 'pending'
        CHECK (processing_status IN ('pending', 'processing', 'completed', 'failed', 'retrying')),
      ADD COLUMN IF NOT EXISTS processing_error TEXT,
      ADD COLUMN IF NOT EXISTS retry_count INTEGER DEFAULT 0,
      ADD COLUMN IF NOT EXISTS chunks_count INTEGER DEFAULT 0,
      ADD COLUMN IF NOT EXISTS vectors_count INTEGER DEFAULT 0,
      ADD COLUMN IF NOT EXISTS processing_started_at TIMESTAMP WITH TIME ZONE,
      ADD COLUMN IF NOT EXISTS processing_completed_at TIMESTAMP WITH TIME ZONE
    `)
    console.log('   âœ… å¤„ç†çŠ¶æ€å­—æ®µæ·»åŠ æˆåŠŸ\n')

    // 3. åˆ›å»ºç´¢å¼•
    console.log('3ï¸âƒ£ åˆ›å»ºç´¢å¼•...')
    await dbClient.query(`
      CREATE INDEX IF NOT EXISTS idx_documents_storage_key ON documents(storage_key);
      CREATE INDEX IF NOT EXISTS idx_documents_content_hash ON documents(content_hash);
      CREATE INDEX IF NOT EXISTS idx_documents_processing_status ON documents(processing_status);
    `)
    console.log('   âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ\n')

    // 4. æ›´æ–°ç°æœ‰è®°å½•çš„ storage_provider
    console.log('4ï¸âƒ£ æ›´æ–°ç°æœ‰è®°å½•çš„ storage_provider...')
    const result = await dbClient.query(`
      UPDATE documents
      SET storage_provider = 'local'
      WHERE storage_provider IS NULL
      RETURNING id
    `)
    console.log(`   âœ… æ›´æ–°äº† ${result.rowCount} æ¡è®°å½•\n`)

    console.log('ğŸ‰ æ•°æ®åº“è¿ç§»å®Œæˆ!\n')
    console.log('ğŸ“‹ æ–°å¢å­—æ®µåˆ—è¡¨:')
    console.log('   - storage_provider (å­˜å‚¨æä¾›å•†)')
    console.log('   - storage_bucket (å­˜å‚¨æ¡¶)')
    console.log('   - storage_key (å¯¹è±¡é”®)')
    console.log('   - content_hash (æ–‡ä»¶å“ˆå¸Œ)')
    console.log('   - processing_status (å¤„ç†çŠ¶æ€)')
    console.log('   - processing_error (å¤„ç†é”™è¯¯)')
    console.log('   - retry_count (é‡è¯•æ¬¡æ•°)')
    console.log('   - chunks_count (å—æ•°é‡)')
    console.log('   - vectors_count (å‘é‡æ•°é‡)')
    console.log('   - processing_started_at (å¤„ç†å¼€å§‹æ—¶é—´)')
    console.log('   - processing_completed_at (å¤„ç†å®Œæˆæ—¶é—´)')

  } catch (error) {
    console.error('âŒ è¿ç§»å¤±è´¥:', error)
    throw error
  } finally {
    await dbClient.close()
  }
}

// è¿è¡Œè¿ç§»
migrateDocumentsSchema().catch(error => {
  console.error('\nâŒ è¿ç§»å¤±è´¥:', error)
  process.exit(1)
})
